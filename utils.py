# HybridGeminiAgent - VERSÃƒO COMPLETA CORRIGIDA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import io
import json
from datetime import datetime
import base64
import re
import streamlit as st
import google.generativeai as genai
from typing import Dict, List, Any, Tuple
from matplotlib.backends.backend_pdf import PdfPages

class HybridGeminiAgent:
    """
    Agente HÃ­brido COMPLETO que combina:
    - LLM (Gemini) para interpretaÃ§Ã£o e insights
    - FunÃ§Ãµes robustas para execuÃ§Ã£o das anÃ¡lises
    - Interface completa da versÃ£o 1
    """
    
    def __init__(self, model_name="gemini-2.5-flash"):  
        self.model_name = model_name
        self.model = None
        self.conversation_history = []
        self.dataset_context = {}
        self.api_key = None
        
        # ConfiguraÃ§Ãµes do Gemini
        self.generation_config = {
            "temperature": 0.3,
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": 2000,
        }
        
        self.safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH", 
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            }
        ]
    
    def configure_gemini(self, api_key=None):
        """Configura o Gemini com a API Key - VERSÃƒO CORRIGIDA"""
        try:
            # 1. Primeiro, tentar obter a API key de diferentes fontes
            if api_key:
                self.api_key = api_key
            elif hasattr(st, 'secrets') and 'GEMINI_API_KEY' in st.secrets:
                self.api_key = st.secrets['GEMINI_API_KEY']
            elif hasattr(st, 'secrets') and 'gemini' in st.secrets and 'api_key' in st.secrets['gemini']:
                self.api_key = st.secrets['gemini']['api_key']
            else:
                st.error("âŒ API Key do Gemini nÃ£o encontrada! Verifique seu arquivo secrets.toml")
                return False
            
            # 2. Configurar o Gemini
            genai.configure(api_key=self.api_key)
            
            # 3. Inicializar o modelo
            self.model = genai.GenerativeModel(
                self.model_name,
                safety_settings=self.safety_settings,
                generation_config=self.generation_config
            )
            
            # 4. Testar a configuraÃ§Ã£o
            test_response = self.model.generate_content("Teste de conexÃ£o. Responda apenas 'OK'")
            
            if test_response and test_response.text:
                st.success("âœ… Gemini configurado com sucesso!")
                return True
            else:
                st.error("âŒ Falha no teste de conexÃ£o com Gemini")
                return False
                
        except Exception as e:
            st.error(f"âŒ Erro ao configurar Gemini: {str(e)}")
            self.model = None
            return False
    
    def _call_gemini(self, prompt: str, system_context: str = "") -> str:
        """Chama Gemini de forma segura com fallback - VERSÃƒO CORRIGIDA"""
        
        # Verificar se o modelo estÃ¡ configurado
        if not self.model:
            # Tentar configurar automaticamente
            if not self.configure_gemini():
                return "âŒ Gemini nÃ£o configurado. Verifique sua API key em secrets.toml"
        
        try:
            # Construir prompt completo
            full_prompt = f"{system_context}\n\n{prompt}" if system_context else prompt
            
            # Fazer a chamada
            response = self.model.generate_content(full_prompt)
            
            # Verificar se hÃ¡ resposta vÃ¡lida
            if response and hasattr(response, 'text') and response.text:
                return response.text
            else:
                return "âš ï¸ Gemini retornou resposta vazia"
                
        except Exception as e:
            error_msg = str(e)
            
            # Tratar erros especÃ­ficos
            if "API_KEY_INVALID" in error_msg:
                return "âŒ API Key invÃ¡lida. Verifique sua chave do Gemini"
            elif "QUOTA_EXCEEDED" in error_msg:
                return "âš ï¸ Cota da API excedida. Tente novamente mais tarde"
            elif "SAFETY" in error_msg:
                return "âš ï¸ ConteÃºdo bloqueado por questÃµes de seguranÃ§a"
            else:
                st.error(f"Erro no Gemini: {error_msg}")
                return f"âŒ Erro na LLM: {error_msg}"
    
    def check_configuration(self):
        """Verifica se o Gemini estÃ¡ configurado corretamente"""
        if not self.model:
            return False, "Modelo nÃ£o inicializado"
        
        if not self.api_key:
            return False, "API Key nÃ£o encontrada"
        
        try:
            # Teste simples
            test_response = self.model.generate_content("Teste")
            return True, "ConfiguraÃ§Ã£o OK"
        except Exception as e:
            return False, f"Erro na configuraÃ§Ã£o: {str(e)}"
    
    def analyze_dataset_initially(self, df: pd.DataFrame) -> Dict[str, Any]:
        """AnÃ¡lise inicial com Gemini + dados estruturados robustos"""
        
        # PARTE 1: AnÃ¡lise robusta (sempre funciona)
        basic_analysis = {
            "shape": df.shape,
            "memory_mb": df.memory_usage(deep=True).sum() / 1024**2,
            "numeric_cols": len(df.select_dtypes(include=[np.number]).columns),
            "categorical_cols": len(df.select_dtypes(include=['object']).columns),
            "missing_values": df.isnull().sum().sum(),
            "completeness": ((df.shape[0] * df.shape[1] - df.isnull().sum().sum()) / (df.shape[0] * df.shape[1]) * 100),
            "duplicates": df.duplicated().sum()
        }
        
        # PARTE 2: InteligÃªncia com Gemini (com fallback)
        system_context = """VocÃª Ã© um especialista em anÃ¡lise de dados. 
        Analise o dataset e forneÃ§a insights contextuais em portuguÃªs."""
        
        prompt = f"""
        Analise este dataset CSV:
        
        DimensÃµes: {df.shape[0]:,} linhas Ã— {df.shape[1]} colunas
        Colunas: {list(df.columns)[:10]}{'...' if len(df.columns) > 10 else ''}
        Tipos: {basic_analysis['numeric_cols']} numÃ©ricas, {basic_analysis['categorical_cols']} categÃ³ricas
        Qualidade: {basic_analysis['completeness']:.1f}% completo, {basic_analysis['duplicates']} duplicatas
        
        Amostra:
        {df.head(3).to_string()}
        
        ForneÃ§a uma anÃ¡lise estruturada:
        1. TIPO DE DATASET: Identifique o domÃ­nio (fraude, vendas, etc.)
        2. CARACTERÃSTICAS PRINCIPAIS: 3 pontos importantes
        3. ANÃLISES RECOMENDADAS: 3 anÃ¡lises mais valiosas
        4. INSIGHTS POTENCIAIS: O que pode ser descoberto
        
        Seja conciso e focado em valor prÃ¡tico.
        """
        
        llm_response = self._call_gemini(prompt, system_context)
        
        # Combinar anÃ¡lises
        result = {
            **basic_analysis,
            "llm_analysis": llm_response,
            "dataset_type": self._extract_dataset_type(llm_response),
            "key_characteristics": self._extract_characteristics(llm_response),
            "recommended_analyses": self._extract_recommendations(llm_response),
            "timestamp": datetime.now().isoformat()
        }
        
        self.dataset_context = result
        return result
    
    def interpret_query_intelligently(self, user_query: str, df: pd.DataFrame) -> Dict[str, Any]:
        """
        HÃBRIDO: LLM interpreta + mapeamento para funÃ§Ãµes robustas
        """
        
        # PARTE 1: InterpretaÃ§Ã£o inteligente com Gemini
        system_context = """VocÃª Ã© um especialista em interpretaÃ§Ã£o de queries sobre anÃ¡lise de dados.
        Classifique a pergunta e forneÃ§a contexto."""
        
        prompt = f"""
        Pergunta do usuÃ¡rio: "{user_query}"
        
        Dataset: {df.shape[0]} linhas, {df.shape[1]} colunas
        Colunas disponÃ­veis: {list(df.columns)[:10]}
        
        Classifique a pergunta em UMA categoria:
        - descriptive: estatÃ­sticas bÃ¡sicas, resumos
        - correlation: correlaÃ§Ãµes, relacionamentos
        - distribution: distribuiÃ§Ãµes, histogramas
        - outliers: outliers, anomalias
        - clustering: agrupamentos, segmentaÃ§Ã£o
        - temporal: padrÃµes temporais, trends
        - frequency: valores frequentes, contagens
        - balance: balanceamento de classes
        - insights: conclusÃµes, descobertas
        - memory: histÃ³rico, memÃ³ria do agente
        
        Responda APENAS com a categoria e coluna(s) se aplicÃ¡vel:
        Formato: categoria|coluna1,coluna2
        Exemplo: correlation|Amount,Time
        """
        
        llm_classification = self._call_gemini(prompt, system_context)
        
        # PARTE 2: Mapeamento robusto (fallback para regras)
        query_lower = user_query.lower()
        
        # Parse da resposta da LLM
        try:
            if '|' in llm_classification:
                category, columns_str = llm_classification.split('|', 1)
                specific_columns = [col.strip() for col in columns_str.split(',') if col.strip()]
            else:
                category = llm_classification.strip()
                specific_columns = []
        except:
            category = "general"
            specific_columns = []
        
        # Fallback para regras se LLM falhar
        if category not in ['descriptive', 'correlation', 'distribution', 'outliers', 
                          'clustering', 'temporal', 'frequency', 'balance', 'insights', 'memory']:
            category = self._fallback_classification(query_lower)
            specific_columns = self._extract_columns_from_query(user_query, df)
        
        return {
            "category": category,
            "specific_columns": specific_columns,
            "original_query": user_query,
            "llm_interpretation": llm_classification,
            "confidence": "high" if '|' in llm_classification else "medium"
        }
    
    def generate_intelligent_response(self, query_result: Dict, analysis_result: Any, df: pd.DataFrame) -> str:
        """
        Gera resposta inteligente combinando resultados tÃ©cnicos com insights da LLM
        """
        
        system_context = """VocÃª Ã© um consultor sÃªnior em dados. 
        Transforme resultados tÃ©cnicos em insights claros e actionables."""
        
        prompt = f"""
        Pergunta original: "{query_result['original_query']}"
        Tipo de anÃ¡lise: {query_result['category']}
        
        Resultados tÃ©cnicos obtidos:
        {str(analysis_result)[:1000] if analysis_result else "AnÃ¡lise executada"}
        
        Dataset context: {self.dataset_context.get('dataset_type', 'Dataset genÃ©rico')}
        
        Gere uma resposta clara que:
        1. Responda diretamente Ã  pergunta
        2. Explique os principais achados
        3. ForneÃ§a insights prÃ¡ticos
        4. Sugira prÃ³ximos passos se relevante
        
        Use linguagem acessÃ­vel e focada em valor de negÃ³cio.
        MÃ¡ximo 300 palavras.
        """
        
        return self._call_gemini(prompt, system_context)
    
    def generate_smart_suggestions(self, df: pd.DataFrame) -> List[str]:
        """Gera sugestÃµes inteligentes baseadas no dataset"""
        
        system_context = """Gere 5 sugestÃµes prÃ¡ticas de perguntas sobre anÃ¡lise de dados."""
        
        prompt = f"""
        Dataset: {self.dataset_context.get('dataset_type', 'GenÃ©rico')}
        Colunas: {list(df.columns)[:8]}
        Shape: {df.shape}
        
        Gere 5 perguntas especÃ­ficas e prÃ¡ticas que um analista faria sobre este dataset.
        
        Formato: uma pergunta por linha, comeÃ§ando com "â€¢"
        Exemplo:
        â€¢ Quais sÃ£o as correlaÃ§Ãµes mais fortes entre as variÃ¡veis numÃ©ricas?
        â€¢ Existem outliers significativos que precisam de investigaÃ§Ã£o?
        """
        
        response = self._call_gemini(prompt, system_context)
        
        suggestions = []
        for line in response.split('\n'):
            line = line.strip()
            if line.startswith('â€¢') or line.startswith('-'):
                suggestion = line[1:].strip()
                if suggestion:
                    suggestions.append(suggestion)
        
        return suggestions[:5]
    
    def generate_executive_conclusions(self, df: pd.DataFrame, memory: Dict) -> str:
        """Gera conclusÃµes executivas com base na memÃ³ria"""
        
        system_context = """VocÃª Ã© um CDO (Chief Data Officer) gerando conclusÃµes executivas."""
        
        # Compilar histÃ³rico
        analyses_summary = []
        for conclusion in memory.get('conclusions', [])[-10:]:
            analyses_summary.append(f"- {conclusion.get('analysis_type', 'N/A')}: {conclusion.get('conclusion', 'N/A')[:100]}")
        
        prompt = f"""
        Dataset analisado: {df.shape[0]:,} registros, {df.shape[1]} variÃ¡veis
        Tipo: {self.dataset_context.get('dataset_type', 'Dataset genÃ©rico')}
        
        AnÃ¡lises realizadas:
        {chr(10).join(analyses_summary[:5])}
        
        Total de anÃ¡lises: {len(memory.get('conclusions', []))}
        
        Gere conclusÃµes executivas estruturadas:
        
        ## ğŸ¯ Resumo Executivo
        [SÃ­ntese em 2-3 frases]
        
        ## ğŸ” Principais Descobertas  
        [3-4 descobertas mais importantes]
        
        ## ğŸ’¼ Impacto no NegÃ³cio
        [Como isso afeta estratÃ©gia/operaÃ§Ãµes]
        
        ## ğŸ¯ RecomendaÃ§Ãµes
        [3-4 aÃ§Ãµes especÃ­ficas recomendadas]
        
        Seja conciso, objetivo e focado em valor executivo.
        """
        
        return self._call_gemini(prompt, system_context)
    
    # === MÃ‰TODOS AUXILIARES ===
    
    def _extract_dataset_type(self, text: str) -> str:
        """Extrai tipo de dataset da resposta da LLM"""
        lines = text.lower().split('\n')
        for line in lines:
            if 'dataset' in line or 'tipo' in line:
                if 'fraude' in line:
                    return 'DetecÃ§Ã£o de Fraude'
                elif 'vendas' in line or 'sales' in line:
                    return 'Dados de Vendas'
                elif 'marketing' in line:
                    return 'Marketing Analytics'
                elif 'financeiro' in line or 'finance' in line:
                    return 'Dados Financeiros'
        return 'Dataset GenÃ©rico'
    
    def _extract_characteristics(self, text: str) -> List[str]:
        """Extrai caracterÃ­sticas da resposta"""
        characteristics = []
        lines = text.split('\n')
        in_characteristics = False
        
        for line in lines:
            if 'caracterÃ­stica' in line.lower() or 'principais' in line.lower():
                in_characteristics = True
                continue
            if in_characteristics and line.strip().startswith(('â€¢', '-', '1.', '2.', '3.')):
                char = re.sub(r'^[â€¢\-\d\.]\s*', '', line.strip())
                if char:
                    characteristics.append(char[:100])
                if len(characteristics) >= 3:
                    break
        
        return characteristics or ['AnÃ¡lise detalhada disponÃ­vel']
    
    def _extract_recommendations(self, text: str) -> List[str]:
        """Extrai recomendaÃ§Ãµes da resposta"""
        recommendations = []
        lines = text.split('\n')
        in_recommendations = False
        
        for line in lines:
            if 'recomend' in line.lower() or 'anÃ¡lise' in line.lower():
                in_recommendations = True
                continue
            if in_recommendations and line.strip().startswith(('â€¢', '-', '1.', '2.', '3.')):
                rec = re.sub(r'^[â€¢\-\d\.]\s*', '', line.strip())
                if rec:
                    recommendations.append(rec[:100])
                if len(recommendations) >= 3:
                    break
        
        return recommendations or ['AnÃ¡lise exploratÃ³ria', 'DetecÃ§Ã£o de padrÃµes']
    
    def _fallback_classification(self, query_lower: str) -> str:
        """ClassificaÃ§Ã£o de fallback baseada em regras"""
        if any(word in query_lower for word in ['correlaÃ§Ã£o', 'relaciona', 'correlation']):
            return 'correlation'
        elif any(word in query_lower for word in ['outlier', 'anomalia', 'atÃ­pico']):
            return 'outliers'
        elif any(word in query_lower for word in ['cluster', 'agrupamento', 'grupo']):
            return 'clustering'
        elif any(word in query_lower for word in ['distribuiÃ§Ã£o', 'histograma']):
            return 'distribution'
        elif any(word in query_lower for word in ['frequente', 'comum', 'contagem']):
            return 'frequency'
        elif any(word in query_lower for word in ['tempo', 'temporal', 'trend']):
            return 'temporal'
        elif any(word in query_lower for word in ['balanceamento', 'balancear']):
            return 'balance'
        elif any(word in query_lower for word in ['conclusÃ£o', 'insight', 'descoberta']):
            return 'insights'
        elif any(word in query_lower for word in ['memÃ³ria', 'histÃ³rico']):
            return 'memory'
        else:
            return 'descriptive'
    
    def _extract_columns_from_query(self, query: str, df: pd.DataFrame) -> List[str]:
        """Extrai nomes de colunas mencionadas na query"""
        columns_mentioned = []
        for col in df.columns:
            if col.lower() in query.lower():
                columns_mentioned.append(col)
        return columns_mentioned

# FUNÃ‡ÃƒO PARA INICIALIZAR O AGENTE NO STREAMLIT
def initialize_hybrid_agent():
    """Inicializa o agente hÃ­brido no Streamlit"""
    
    # Verificar se jÃ¡ existe na sessÃ£o
    if 'hybrid_agent' not in st.session_state:
        st.session_state.hybrid_agent = HybridGeminiAgent()
    
    # Verificar configuraÃ§Ã£o
    agent = st.session_state.hybrid_agent
    is_configured, status = agent.check_configuration()
    
    if not is_configured:
        st.warning(f"âš ï¸ Configurando Gemini... Status: {status}")
        
        # Tentar configurar
        success = agent.configure_gemini()
        
        if not success:
            st.error("""
            âŒ **Erro na configuraÃ§Ã£o do Gemini**
            
            Verifique se:
            1. O arquivo `.streamlit/secrets.toml` existe
            2. ContÃ©m sua API key: `GEMINI_API_KEY = "sua_chave_aqui"`
            3. A chave Ã© vÃ¡lida no Google AI Studio
            
            **Como obter a API key:**
            - Acesse: https://aistudio.google.com/app/apikey
            - Crie uma nova chave
            - Adicione ao secrets.toml
            """)
            return None
    
    return agent

# VERIFICAÃ‡ÃƒO DE SECRETS.TOML
def verificar_secrets():
    """FunÃ§Ã£o para verificar se os secrets estÃ£o configurados"""
    try:
        # MÃ©todo 1: GEMINI_API_KEY diretamente
        if hasattr(st, 'secrets') and 'GEMINI_API_KEY' in st.secrets:
            key = st.secrets['GEMINI_API_KEY']
            if key and len(key) > 30:  # API keys do Google sÃ£o longas
                return True, "âœ… GEMINI_API_KEY encontrada"
            else:
                return False, "âŒ GEMINI_API_KEY muito curta ou vazia"
        
        # MÃ©todo 2: gemini.api_key
        elif hasattr(st, 'secrets') and 'gemini' in st.secrets:
            if 'api_key' in st.secrets['gemini']:
                key = st.secrets['gemini']['api_key']
                if key and len(key) > 30:
                    return True, "âœ… gemini.api_key encontrada"
                else:
                    return False, "âŒ gemini.api_key muito curta ou vazia"
        
        return False, "âŒ Nenhuma API key encontrada em secrets.toml"
        
    except Exception as e:
        return False, f"âŒ Erro ao verificar secrets: {str(e)}"

# Adicione isso temporariamente para verificar a configuraÃ§Ã£o
if st.sidebar.button("ğŸ”§ Debug Gemini"):
    has_secrets, message = verificar_secrets()
    st.sidebar.write(message)
    
    if has_secrets:
        agent = st.session_state.hybrid_agent
        is_configured, status = agent.check_configuration()
        st.sidebar.write(f"Status: {status}")
        
        if is_configured:
            response = agent._call_gemini("Teste rÃ¡pido")
            st.sidebar.success(f"Funcionando: {response[:50]}...")
